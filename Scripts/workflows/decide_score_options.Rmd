---
title: "DECIDE Score"
author: "Thomas MM; Tom A"
date: "4/8/2021"
output: html_document
---

```{r setup, include=FALSE, echo = FALSE}

knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE)

library(spatstat)
library(tidyverse)
library(raster)
library(foreach)
library(doParallel)


source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/filter_distance.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/recommend_rank.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/recommend_metric.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/recommend_agg_rank.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/extract_metric.R")


```

## Load species data

```{r species_data, warning=FALSE}

model = c('rf', 'lr', 'gam')
taxa = 'moth'

# get a list of all the species that appear in the outputs
spp_names_lr <- unique(gsub(pattern="lr_SDMs_|_meanpred.grd|_quantilemaxmin.grd|_quantilerange.grd", replacement = '', 
                            x = list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/lr'), pattern = '.grd')))

spp_names_rf <- unique(gsub(pattern="rf_SDMs_|_meanpred.grd|_quantilemaxmin.grd|_quantilerange.grd", replacement = '', 
                            x = list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/rf'), pattern = '.grd')))

spp_names_gam <- unique(gsub(pattern="gam_SDMs_|_meanpred.grd|_quantilemaxmin.grd|_quantilerange.grd", replacement = '', 
                             x = list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/gam'), pattern = '.grd')))

names <- unique(c(spp_names_lr, spp_names_rf, spp_names_gam))

# sdm outputs for each species
species_stack <- list()

# error outputs
error_out <- list()

for(i in 1:length(names)){
  
  print(names[i])
  
  # initiate model list within for loop so that it gets replaced when starting a new species
  # otherwise we might get some weird overlaps
  model_stack <- list()
  errored_models <- list()
  
  for(m in 1:length(model)){
    
    check_models <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                               pattern = paste0(names[i]),
                               full.names = TRUE)
    
    if(length(check_models)<=1){
      
      print(paste('!!!   model', model[m], 'failed for species', names[i], '  !!!'))
      
      errored_models[[m]] <- data.frame(taxa = taxa, 
                                        species = names[i], 
                                        model = model[m])
      
      next
    }
    
    # mean predictions
    mp <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                     pattern = paste0(names[i], "_meanpred.grd"),
                     full.names = TRUE)
    
    mod_preds <- raster::stack(mp)
    names(mod_preds) <- paste0(names[i], '_', model[m],'_mean_pred')
    
    
    
    # quantile min/max
    mm <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                     pattern = paste0(names[i], "_quantilemaxmin.grd"),
                     full.names = TRUE)
    
    qminmax <- raster::stack(mm)
    names(qminmax) <- c(paste0(names[i], '_', model[m],'_min'), paste0(names[i], '_', model[m],'_max'))
    
    
    # quantile range
    qr <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                     pattern = paste0(names[i], "_quantilerange.grd"),
                     full.names = TRUE)
    
    qrange <- raster::stack(qr)
    names(qrange) <- paste0(names[i], '_', model[m], '_quantile_range')
    
    
    # stack all from one model together
    model_stack[[m]] <- raster::stack(mod_preds, qminmax, qrange)
    
  }
  
  # model_stack[sapply(model_stack,is.null)] <- raster(nrow=12500, 
  #                                                    ncol=7000,
  #                                                    crs="+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs")
  
  # To combine them together need to remove the NULL raster layers (i.e. if a model hasn't worked)
  model_stack <- model_stack[!sapply(model_stack,is.null)]
  
  species_stack[[i]] <- raster::stack(model_stack)
  
  # Output the models that failed too
  error_out[[i]] <- do.call('rbind', errored_models) 
  
}

# which models didn't work
errors <- do.call('rbind', error_out)
errors

# name the list entries
names(species_stack) <- names

```


## crop species to smaller scale


```{r cropping, warning=FALSE}

# set location 
location = c(-2.730696, 54.026759) # quernmore
# location = c(-1.110557, 51.602436) # wallingford

# distances
distance = 5000


registerDoParallel(7)

# out_cropped <- list()
system.time(
  out_cropped <- foreach(s = 1:length(species_stack)) %dopar% {
    
    print(s)
    
    sp <- species_stack[[s]]
    
    
    # crop the prediction
    crop_pred <- filter_distance(obj = subset(sp, grep(pattern = 'mean_pred',
                                                       names(sp))),
                                 method = 'buffer',
                                 distance = distance,
                                 location = location)
    
    # crop the error
    crop_err <- filter_distance(obj = subset(sp, grep(pattern = 'quantile_range',
                                                      names(sp))),
                                method = 'buffer',
                                distance = distance,
                                location = location)
    
    if(length(names(crop_pred))>1){
      # get the mean
      m_pred_av <- calc(crop_pred,
                        mean, na.rm = T)
      names(m_pred_av) <- 'predictions'
      
      
      m_quant_av <- calc(crop_err,
                         mean, na.rm = T)
      names(m_quant_av) <- 'error'
    } else {
      
      m_pred_av <- crop_err
      m_quant_av <- crop_err
      
    }
    
    out_rasts <- list(m_pred_av, m_quant_av)
    names(out_rasts) <- c('predictions', 'quantile_var')
    
    return(out_rasts)
    
  }
)

registerDoSEQ()

names(out_cropped) <- names

```




## different DECIDE score options

### Score for a single species

```{r score, fig.height=8, fig.width=10, warning=FALSE}

score <- recommend_metric(prediction_raster = out_cropped$Adscita_geryon$predictions,
                          error_raster = out_cropped$Adscita_geryon$quantile_var)

par(mfrow = c(2,2))
plot(out_cropped$Adscita_geryon$predictions, main = 'prediction')
plot(out_cropped$Adscita_geryon$quantile_var, main = 'variation')

plot(score$multiply, main = names(score)[1])
plot(score$additive, main = names(score)[2])
par(mfrow = c(1,1))


```


```{r score_mult_spp, warning = FALSE}

score_mult <- lapply(c(1:length(out_cropped)), FUN = function(x){
  
  rm <- recommend_metric(prediction_raster = out_cropped[[x]]$predictions,
                         error_raster = out_cropped[[x]]$quantile_var,
                         method = 'multiply')$multiply
  
  return(rm)
  
})

names(score_mult) <- names(out_cropped)


```


Makes most sense to use the multiplicative method of combining probability of presence and variation layers.

Join the different species together by averaging the decide score weighted by the mean probability of presence across the subsetted area to remove species with low prob of being there... Or maybe weight by the maximum probability of presence so that species only present in a very specific habitat aren't too downweighted 

## How to combine DECIDE score across species?

Multiple potential options to test:

1. take sum across species
2. take the mean across species
3. weighted average based on maximum probability of presence within region
4. weighted average based on maximum probability of presence within larger region (~30km?)
5. weighted average based on national scarcity

All of these with an arithmetic mean vs geometric mean.


```{r 1_comb_arithmetic, warning = F}

# get the cropped probability of presence
preds <- stack(lapply(1:length(out_cropped), FUN = function(x) out_cropped[[x]]$predictions))
names(preds) <- names(out_cropped)


## 1.
sum_1 <- calc(stack(score_mult), sum)
plot(sum_1, main = '1. Sum')

## 2.
mean_2 <- calc(stack(score_mult), mean)
plot(mean_2, main = '2. arithmetic mean')

## 3. 
arit_weight_max_3 <- weighted.mean(stack(score_mult), cellStats(stack(preds), max))
plot(arit_weight_max_3, main = '3. arith_mean weighted by max prob. pres.')

## 4.
# function to get the corresponding layer of interest in a raster stack
# takes a list of stacks and the layer name to use
get_layer <- function(layer_stack, pattern) return(lapply(layer_stack, FUN = function(x) subset(x, grep(pattern = pattern, names(x)))))

preds_uk <- get_layer(species_stack, pattern = 'mean_pred') # get the mean preds layer

# crop the uk-wide predictions to 30km around region
crop_30 <- mcmapply(preds_uk, FUN = function(x) filter_distance(obj = x, method = 'buffer', distance = 30000, location = location))

# just get the mean across all models (will have to be weighted by AUC later on in life)
preds_30km_mn <- sapply(1:length(crop_30), FUN = function(x) if(nlayers(crop_30[[x]])==1) {crop_30[[x]]} else {calc(crop_30[[x]], mean, na.rm = T)})

arit_weight_max30km_4 <- weighted.mean(stack(score_mult), cellStats(stack(preds_30km_mn), max)) # do the mean weighted by the max probability of presence within 30km
plot(arit_weight_max30km_4, main = '4. arith_mean weighted by max prob. pres. 30km')

## 5. 
# function to rescale between 0 and 1
range01 <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}

# first, get scarcity
dfm_prev <- dfm %>% group_by(sp_n) %>% 
  mutate(n_cells = length(unique(TO_GRIDREF))) %>% # number unique locations
  ungroup() %>% 
  mutate(prev = n_cells/length(unique(TO_GRIDREF))) %>% # get the prevalence of each species relative to the total number of grid cells sampled
  dplyr::select(sp_n, n_cells, prev) %>% # select only columns of interest
  distinct() %>% 
  mutate(rescal_prev = range01(prev), # rescale range between 0 and 1
         sp_n = gsub(pattern = ' ', replacement = '_', x = sp_n))

dfm_prev

# now need to match species names between the prevalence df and raster layer names
score_mult[[which(names(score_mult)==dfm_prev$sp_n[1])]]

# or possibly in alphabetical order...?
dfm_prev$sp_n
names(score_mult)
## no - doesn't work cos species dropped...

# get weightings first
ukprev_wts <- sapply(1:length(score_mult), FUN = function(x) dfm_prev$rescal_prev[dfm_prev$sp_n==names(score_mult)[x]])
1.000001-ukprev_wts # get the inverse weights to give least prevalent species highest rating. Add a tiny bit so the most abundant species doesn't get a 0-weight

arit_weight_ukprev_5 <- weighted.mean(stack(score_mult), 1.000001-ukprev_wts)
plot(arit_weight_ukprev_5, main = '5. arith_mean weighted by national scarcity')


```





```{r geo_mean, warning = FALSE}

# unweighted geometric mean
gm_mean = function(x, na.rm=FALSE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}

# weighted geometric mean
weighted.geomean <- function(x, w, ...){
  return(prod(x^w, ...)^(1/sum(w)))
}

## 1.
sum_1 <- calc(stack(score_mult), sum)
plot(sum_1, main = '1. Sum')

## 2. 
geo_mean_2 <- calc(stack(score_mult), gm_mean)
plot(geo_mean_2, main = '2. geometric mean')

## 3. 
geo_weight_max_3 <- weighted.geomean(stack(score_mult), cellStats(stack(preds), max))
plot(geo_weight_max_3, main = '3. geo_mean weighted by max prob. pres.')

## 4.
geo_weight_max30km_4 <- weighted.geomean(stack(score_mult), cellStats(stack(preds_30km_mn), max)) # do the mean weighted by the max probability of presence within 30km
plot(geo_weight_max30km_4, main = '4. geo_mean weighted by max prob. pres. 30km')

## 5. 
# function to rescale between 0 and 1
range01 <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}

# first, get scarcity
dfm_prev <- dfm %>% group_by(sp_n) %>% 
  mutate(n_cells = length(unique(TO_GRIDREF))) %>% # number unique locations
  ungroup() %>% 
  mutate(prev = n_cells/length(unique(TO_GRIDREF))) %>% # get the prevalence of each species relative to the total number of grid cells sampled
  dplyr::select(sp_n, n_cells, prev) %>% # select only columns of interest
  distinct() %>% 
  mutate(rescal_prev = range01(prev), # rescale range between 0 and 1
         sp_n = gsub(pattern = ' ', replacement = '_', x = sp_n))

dfm_prev

# now need to match species names between the prevalence df and raster layer names
score_mult[[which(names(score_mult)==dfm_prev$sp_n[1])]]

# or possibly in alphabetical order...?
dfm_prev$sp_n
names(score_mult)
## no - doesn't work cos species dropped...

# get weightings first
ukprev_wts <- sapply(1:length(score_mult), FUN = function(x) dfm_prev$rescal_prev[dfm_prev$sp_n==names(score_mult)[x]])
1.000001-ukprev_wts # get the inverse weights to give least prevalent species highest rating. Add a tiny bit so the most abundant species doesn't get a 0-weight

geo_weight_ukprev_5 <- weighted.geomean(stack(score_mult), 1.000001-ukprev_wts)
plot(geo_weight_ukprev_5, main = '5. geo_mean weighted by national scarcity')


```

```{r all_ps, fig.width=12, meassage = F, warning=F}

par(mfrow =c(2,4))

plot(mean_2, main = '2. arithmetic mean')
plot(arit_weight_max_3, main = '3. arith_mean, wt max prob. pres.')
plot(arit_weight_max30km_4, main = '4. arith_mean, wt max prob. pres. 30km')
plot(arit_weight_ukprev_5, main = '5. arith_mean, wt national scarcity')

plot(geo_mean_2, main = '2. geometric mean')
plot(geo_weight_max_3, main = '3. geo_mean, wt max prob. pres.')
plot(geo_weight_max30km_4, main = '4. geo_mean, wt max prob. pres. 30km')
plot(geo_weight_ukprev_5, main = '5. geo_mean, wt national scarcity')

par(mfrow=c(1,1))

```


```{r comb_old, fig.height=8, fig.width=10}



## calculate multiplied
mean_mult <- weighted.mean(stack(score_mult), cellStats(preds, mean))
max_mult <- weighted.mean(stack(score_mult), cellStats(preds, max))

# calculate additions
mean_add <- weighted.mean(stack(score_add), cellStats(stack(preds), mean))
max_add <- weighted.mean(stack(score_add), cellStats(stack(preds), max))

# plot
par(mfrow=c(2,2))
plot(mean_mult, main = 'mean weighted multiply')
plot(max_mult, main = 'max weighted multiply')

plot(mean_add, main = 'mean weighted additive')
plot(max_add, main = 'max weighted additive')
par(mfrow=c(1,1))



```







