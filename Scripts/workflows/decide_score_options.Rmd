---
title: "DECIDE Score"
author: "Thomas MM; Tom A"
date: "4/8/2021"
output: html_document
---

```{r setup, include=FALSE, echo = FALSE}

knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE)

library(spatstat)
library(tidyverse)
library(raster)
library(foreach)
library(doParallel)


source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/filter_distance.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/recommend_rank.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/recommend_metric.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/recommend_agg_rank.R")
source("/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Scripts/modules/extract_metric.R")


```

## Load species data

```{r species_data, warning=FALSE}

model = c('rf', 'lr', 'gam')
taxa = 'moth'

# get a list of all the species that appear in the outputs
spp_names_lr <- unique(gsub(pattern="lr_SDMs_|_meanpred.grd|_quantilemaxmin.grd|_quantilerange.grd", replacement = '', 
                            x = list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/lr'), pattern = '.grd')))

spp_names_rf <- unique(gsub(pattern="rf_SDMs_|_meanpred.grd|_quantilemaxmin.grd|_quantilerange.grd", replacement = '', 
                            x = list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/rf'), pattern = '.grd')))

spp_names_gam <- unique(gsub(pattern="gam_SDMs_|_meanpred.grd|_quantilemaxmin.grd|_quantilerange.grd", replacement = '', 
                             x = list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/gam'), pattern = '.grd')))

names <- unique(c(spp_names_lr, spp_names_rf, spp_names_gam))

# sdm outputs for each species
species_stack <- list()

# error outputs
error_out <- list()

for(i in 1:length(names)){
  
  print(names[i])
  
  # initiate model list within for loop so that it gets replaced when starting a new species
  # otherwise we might get some weird overlaps
  model_stack <- list()
  errored_models <- list()
  
  for(m in 1:length(model)){
    
    check_models <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                               pattern = paste0(names[i]),
                               full.names = TRUE)
    
    if(length(check_models)<=1){
      
      print(paste('!!!   model', model[m], 'failed for species', names[i], '  !!!'))
      
      errored_models[[m]] <- data.frame(taxa = taxa, 
                                        species = names[i], 
                                        model = model[m])
      
      next
    }
    
    # mean predictions
    mp <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                     pattern = paste0(names[i], "_meanpred.grd"),
                     full.names = TRUE)
    
    mod_preds <- raster::stack(mp)
    names(mod_preds) <- paste0(names[i], '_', model[m],'_mean_pred')
    
    
    
    # quantile min/max
    mm <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                     pattern = paste0(names[i], "_quantilemaxmin.grd"),
                     full.names = TRUE)
    
    qminmax <- raster::stack(mm)
    names(qminmax) <- c(paste0(names[i], '_', model[m],'_min'), paste0(names[i], '_', model[m],'_max'))
    
    
    # quantile range
    qr <- list.files(paste0('/data-s3/thoval/sdm_outputs/', taxa, '/', model[m]), 
                     pattern = paste0(names[i], "_quantilerange.grd"),
                     full.names = TRUE)
    
    qrange <- raster::stack(qr)
    names(qrange) <- paste0(names[i], '_', model[m], '_quantile_range')
    
    
    # stack all from one model together
    model_stack[[m]] <- raster::stack(mod_preds, qminmax, qrange)
    
  }
  
  # model_stack[sapply(model_stack,is.null)] <- raster(nrow=12500, 
  #                                                    ncol=7000,
  #                                                    crs="+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs")
  
  # To combine them together need to remove the NULL raster layers (i.e. if a model hasn't worked)
  model_stack <- model_stack[!sapply(model_stack,is.null)]
  
  species_stack[[i]] <- raster::stack(model_stack)
  
  # Output the models that failed too
  error_out[[i]] <- do.call('rbind', errored_models) 
  
}

# which models didn't work
errors <- do.call('rbind', error_out)
errors

# name the list entries
names(species_stack) <- names

```


## Create a moth counts raster


```{r counts, echo=FALSE}
# 
# ##  create a 'counts' raster layer  
# dfm <- read.csv('/data/notebooks/rstudio-adaptsampthomas/DECIDE_adaptivesampling/Data/species_data/moth/DayFlyingMoths_East_Norths.csv')
# head(dfm)
# 
# xy <- dfm[,c("lon","lat")]
# spdf.moth <- SpatialPointsDataFrame(coords = xy, data = dfm,
#                                     proj4string = CRS("+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs")) 
# 
# # plot(spdf.moth) ## check with plot
# 
# ### create temporary raster to store number of records in each cell ###
# moth_counts <- species_stack[[1]][[1]] # get a single raster
# 
# # make a raster of zeroes for input
# moth_counts[!is.na(moth_counts)] <- 0
# 
# # get the cell index for each point and make a table:
# counts = table(cellFromXY(moth_counts,spdf.moth))
# 
# # fill in the raster with the counts from the cell index:
# moth_counts[as.numeric(names(counts))] <- counts
# plot(moth_counts)
# hist(moth_counts) ## loads of cells with no counts in so probably useless as a layer
# 
# ## counts for susan
# # number of days of sighting of any species for each grid cell
# # first get number of days of sighting 
# 
# km1_eff <- dfm %>% 
#   group_by(lon,lat) %>% 
#   summarise(effort = length(unique(date))) %>% 
#   arrange(-effort)
# 
# r_df <- as.data.frame(moth_counts, xy=T)[,1:2]
# 
# r_df %>% 
#   mutate(eff)
# 
# 
# r_df$effort <- km1_eff$effort[match(paste0(r_df$x, r_df$y), paste0(km1_eff$lon, km1_eff$lat))]
# 
# 
# km1_eff %>% 
#   ggplot() +
#   geom_histogram(aes(x = effort)) +
#   theme_classic()
# 
# xy_eff <- km1_eff[,c("lon","lat")]
# spdf.moth_eff <- SpatialPointsDataFrame(coords = xy_eff, data = km1_eff,
#                                     proj4string = CRS("+proj=tmerc +lat_0=49 +lon_0=-2 +k=0.9996012717 +x_0=400000 +y_0=-100000 +ellps=airy +units=m +no_defs")) 
# 
# moth_eff_1km <- species_stack[[1]][[1]] # get a single raster
# 
# # make a raster of zeroes for input
# moth_eff_1km[!is.na(moth_eff_1km)] <- 0
# 
# # get the cell index for each point and make a table:
# effort = table(cellFromXY(moth_eff_1km,spdf.moth_eff))
# hist(effort)
# 
# # fill in the raster with the counts from the cell index:
# moth_eff_1km[as.numeric(names(effort))] <- effort
# plot(moth_eff_1km)
# 
# round(dfm$lon[1])

```


loads of cells with no counts in so probably useless as a layer


## kernel density


```{r kern_dens, fig.height=8, fig.width=8, message=FALSE, warning=FALSE}
# 
# sigma = 10000 # decide number of metres to calculate points over
# 
# moth_ppp <- ppp(x = dfm[,c("lon")], y = dfm[,c("lat")],
#                 owin(xrange = c(extent(moth_counts)[1], extent(moth_counts)[2]),
#                      yrange = c(extent(moth_counts)[3], extent(moth_counts)[4])))
# 
# 
# dp <- stats::density(moth_ppp, sigma = sigma) 
# dpr <- raster(dp)
# re_dpr <- resample(dpr, moth_counts, method = 'ngb')
# kernel_moth <- mask(re_dpr, moth_counts) # mask to remove sea
# plot(kernel_moth)
# 
# kern_dens <- function(data, sigma, rast){
#   
#   
#   moth_ppp <- ppp(x = data[,c("lon")], y = data[,c("lat")],
#                   owin(xrange = c(extent(rast)[1], extent(rast)[2]),
#                        yrange = c(extent(rast)[3], extent(rast)[4])))
#   
#   
#   dp <- density(moth_ppp, sigma = sigma) 
#   dpr <- raster(dp)
#   re_dpr <- resample(dpr, rast, method = 'ngb')
#   kernel_moth <- mask(re_dpr, rast) # mask to remove sea
#   
# }
# 
# par(mfrow = c(2,2))
# 
# for(i in c(1, 10, 100, 20000)){
#   
#   out <- kern_dens(data = dfm, rast = moth_counts, sigma = i)
#   
#   plot(out, main = paste('grouping distance =', i))
#   
# }
# 
# 
# for(i in c(1, 10, 100, 20000)){
#   
#   out <- kern_dens(data = dfm, rast = moth_counts, sigma = i)
#   
#   out_inv <- 1/out
#   
#   plot(log(out_inv), main = paste('inversed grouping distance =', i))
#   
# }
# 
# par(mfrow = c(1,1))

```

## crop species to smaller scale


```{r cropping, warning=FALSE}

# set location 
location = c(-2.730696, 54.026759) # quernmore
# location = c(-1.110557, 51.602436) # wallingford

# distances
distance = 5000


registerDoParallel(7)

# out_cropped <- list()
system.time(
  out_cropped <- foreach(s = 1:length(species_stack)) %dopar% {
    
    print(s)
    
    sp <- species_stack[[s]]
    
    
    # crop the prediction
    crop_pred <- filter_distance(obj = subset(sp, grep(pattern = 'mean_pred',
                                                       names(sp))),
                                 method = 'buffer',
                                 distance = distance,
                                 location = location)
    
    # crop the error
    crop_err <- filter_distance(obj = subset(sp, grep(pattern = 'quantile_range',
                                                      names(sp))),
                                method = 'buffer',
                                distance = distance,
                                location = location)
    
    if(length(names(crop_pred))>1){
      # get the mean
      m_pred_av <- calc(crop_pred,
                        mean, na.rm = T)
      names(m_pred_av) <- 'predictions'
      
      
      m_quant_av <- calc(crop_err,
                         mean, na.rm = T)
      names(m_quant_av) <- 'error'
    } else {
      
      m_pred_av <- crop_err
      m_quant_av <- crop_err
      
    }
    
    out_rasts <- list(m_pred_av, m_quant_av)
    names(out_rasts) <- c('predictions', 'quantile_var')
    
    return(out_rasts)
    
  }
)

registerDoSEQ()

names(out_cropped) <- names

```



```{r crop_moth_count}
# 
# inv_kern_50 <- 1/kern_dens(data = dfm, rast = species_stack[[1]][[1]], sigma = 50)
# inv_kern_100 <- 1/kern_dens(data = dfm, rast = moth_counts, sigma = 100)
# 
# crop_kern_100 <- filter_distance(inv_kern_50, 
#                                  location = location,
#                                  method = 'buffer',
#                                  distance = distance)
# plot(crop_kern_100)
# 
# plot(inv_kern_100)

```

**That is not what I was expecting in terms of resolution - check the code.**



## different DECIDE score options

### Score for a single species

```{r score, fig.height=8, fig.width=10, warning=FALSE}

score <- recommend_metric(prediction_raster = out_cropped$Adscita_geryon$predictions,
                          error_raster = out_cropped$Adscita_geryon$quantile_var)

par(mfrow = c(2,2))
plot(out_cropped$Adscita_geryon$predictions, main = 'prediction')
plot(out_cropped$Adscita_geryon$quantile_var, main = 'variation')

plot(score$multiply, main = names(score)[1])
plot(score$additive, main = names(score)[2])
par(mfrow = c(1,1))


```


```{r score_mult_spp, warning = FALSE}

score_mult <- lapply(c(1:length(out_cropped)), FUN = function(x){
  
  rm <- recommend_metric(prediction_raster = out_cropped[[x]]$predictions,
                         error_raster = out_cropped[[x]]$quantile_var,
                         method = 'multiply')$multiply
  
  return(rm)
  
})

names(score_mult) <- names(out_cropped)


score_add <- lapply(c(1:length(out_cropped)), FUN = function(x){
  
  rm <- recommend_metric(prediction_raster = out_cropped[[x]]$predictions,
                         error_raster = out_cropped[[x]]$quantile_var,
                         method = 'additive')$additive
  
  return(rm)
  
})

names(score_add) <- names(out_cropped)

```


Makes most sense to use the multiplicative method of combining probability of presence and variation layers.

Join the different species together by averaging the decide score weighted by the mean probability of presence across the subsetted area to remove species with low prob of being there... Or maybe weight by the maximum probability of presence so that species only present in a very specific habitat aren't too downweighted 

## How to combine DECIDE score across species?

Multiple potential options to test:

1. take sum across species
2. take the mean across species
3. weighted average based on maximum probability of presence within region
4. weighted average based on maximum probability of presence within larger region (~30km?)
5. weighted average based on national scarcity

All of these with an arithmetic mean vs geometric mean.


```{r 1_comb_arithmetic, warning = F}

# get the cropped probability of presence
preds <- stack(lapply(1:length(out_cropped), FUN = function(x) out_cropped[[x]]$predictions))
names(preds) <- names(out_cropped)


## 1.
sum_1 <- calc(stack(score_mult), sum)
plot(sum_1, main = '1. Sum')

## 2.
mean_2 <- calc(stack(score_mult), mean)
plot(mean_2, main = '2. arithmetic mean')

## 3. 
arit_weight_max_3 <- weighted.mean(stack(score_mult), cellStats(stack(preds), max))
plot(arit_weight_max_3, main = '3. arith_mean weighted by max prob. pres.')

## 4.
# function to get the corresponding layer of interest in a raster stack
# takes a list of stacks and the layer name to use
get_layer <- function(layer_stack, pattern) return(lapply(layer_stack, FUN = function(x) subset(x, grep(pattern = pattern, names(x)))))

preds_uk <- get_layer(species_stack, pattern = 'mean_pred') # get the mean preds layer

# crop the uk-wide predictions to 30km around region
crop_30 <- mcmapply(preds_uk, FUN = function(x) filter_distance(obj = x, method = 'buffer', distance = 30000, location = location))

# just get the mean across all models (will have to be weighted by AUC later on in life)
preds_30km_mn <- sapply(1:length(crop_30), FUN = function(x) if(nlayers(crop_30[[x]])==1) {crop_30[[x]]} else {calc(crop_30[[x]], mean, na.rm = T)})

arit_weight_max30km_4 <- weighted.mean(stack(score_mult), cellStats(stack(preds_30km_mn), max)) # do the mean weighted by the max probability of presence within 30km
plot(arit_weight_max30km_4, main = '4. arith_mean weighted by max prob. pres. 30km')

## 5. 
# function to rescale between 0 and 1
range01 <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}

# first, get scarcity
dfm_prev <- dfm %>% group_by(sp_n) %>% 
  mutate(n_cells = length(unique(TO_GRIDREF))) %>% # number unique locations
  ungroup() %>% 
  mutate(prev = n_cells/length(unique(TO_GRIDREF))) %>% # get the prevalence of each species relative to the total number of grid cells sampled
  dplyr::select(sp_n, n_cells, prev) %>% # select only columns of interest
  distinct() %>% 
  mutate(rescal_prev = range01(prev), # rescale range between 0 and 1
         sp_n = gsub(pattern = ' ', replacement = '_', x = sp_n))

dfm_prev

# now need to match species names between the prevalence df and raster layer names
score_mult[[which(names(score_mult)==dfm_prev$sp_n[1])]]

# or possibly in alphabetical order...?
dfm_prev$sp_n
names(score_mult)
## no - doesn't work cos species dropped...

# get weightings first
ukprev_wts <- sapply(1:length(score_mult), FUN = function(x) dfm_prev$rescal_prev[dfm_prev$sp_n==names(score_mult)[x]])
1.000001-ukprev_wts # get the inverse weights to give least prevalent species highest rating. Add a tiny bit so the most abundant species doesn't get a 0-weight

arit_weight_ukprev_5 <- weighted.mean(stack(score_mult), 1.000001-ukprev_wts)
plot(arit_weight_ukprev_5, main = '5. arith_mean weighted by national scarcity')


```





```{r geo_mean, warning = FALSE}

# unweighted geometric mean
gm_mean = function(x, na.rm=FALSE){
  exp(sum(log(x[x > 0]), na.rm=na.rm) / length(x))
}

# weighted geometric mean
weighted.geomean <- function(x, w, ...){
  return(prod(x^w, ...)^(1/sum(w)))
}

## 1.
sum_1 <- calc(stack(score_mult), sum)
plot(sum_1, main = '1. Sum')

## 2. 
geo_mean_2 <- calc(stack(score_mult), gm_mean)
plot(geo_mean_2, main = '2. geometric mean')

## 3. 
geo_weight_max_3 <- weighted.geomean(stack(score_mult), cellStats(stack(preds), max))
plot(geo_weight_max_3, main = '3. geo_mean weighted by max prob. pres.')

## 4.
geo_weight_max30km_4 <- weighted.geomean(stack(score_mult), cellStats(stack(preds_30km_mn), max)) # do the mean weighted by the max probability of presence within 30km
plot(geo_weight_max30km_4, main = '4. geo_mean weighted by max prob. pres. 30km')

## 5. 
# function to rescale between 0 and 1
range01 <- function(x, ...){(x - min(x, ...)) / (max(x, ...) - min(x, ...))}

# first, get scarcity
dfm_prev <- dfm %>% group_by(sp_n) %>% 
  mutate(n_cells = length(unique(TO_GRIDREF))) %>% # number unique locations
  ungroup() %>% 
  mutate(prev = n_cells/length(unique(TO_GRIDREF))) %>% # get the prevalence of each species relative to the total number of grid cells sampled
  dplyr::select(sp_n, n_cells, prev) %>% # select only columns of interest
  distinct() %>% 
  mutate(rescal_prev = range01(prev), # rescale range between 0 and 1
         sp_n = gsub(pattern = ' ', replacement = '_', x = sp_n))

dfm_prev

# now need to match species names between the prevalence df and raster layer names
score_mult[[which(names(score_mult)==dfm_prev$sp_n[1])]]

# or possibly in alphabetical order...?
dfm_prev$sp_n
names(score_mult)
## no - doesn't work cos species dropped...

# get weightings first
ukprev_wts <- sapply(1:length(score_mult), FUN = function(x) dfm_prev$rescal_prev[dfm_prev$sp_n==names(score_mult)[x]])
1.000001-ukprev_wts # get the inverse weights to give least prevalent species highest rating. Add a tiny bit so the most abundant species doesn't get a 0-weight

geo_weight_ukprev_5 <- weighted.geomean(stack(score_mult), 1.000001-ukprev_wts)
plot(geo_weight_ukprev_5, main = '5. geo_mean weighted by national scarcity')


```

```{r all_ps, fig.width=12}

par(mfrow =c(2,4))

plot(mean_2, main = '2. arithmetic mean')
plot(arit_weight_max_3, main = '3. arith_mean weighted by max prob. pres.')
plot(arit_weight_max30km_4, main = '4. arith_mean weighted by max prob. pres. 30km')
plot(arit_weight_ukprev_5, main = '5. arith_mean weighted by national scarcity')

plot(geo_mean_2, main = '2. geometric mean')
plot(geo_weight_max_3, main = '3. geo_mean weighted by max prob. pres.')
plot(geo_weight_max30km_4, main = '4. geo_mean weighted by max prob. pres. 30km')
plot(geo_weight_ukprev_5, main = '5. geo_mean weighted by national scarcity')

par(mfrow=c(1,1))

```


```{r comb_old, fig.height=8, fig.width=10}



## calculate multiplied
mean_mult <- weighted.mean(stack(score_mult), cellStats(preds, mean))
max_mult <- weighted.mean(stack(score_mult), cellStats(preds, max))

# calculate additions
mean_add <- weighted.mean(stack(score_add), cellStats(stack(preds), mean))
max_add <- weighted.mean(stack(score_add), cellStats(stack(preds), max))

# plot
par(mfrow=c(2,2))
plot(mean_mult, main = 'mean weighted multiply')
plot(max_mult, main = 'max weighted multiply')

plot(mean_add, main = 'mean weighted additive')
plot(max_add, main = 'max weighted additive')
par(mfrow=c(1,1))



```







